{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Cough Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsHMT9pquqHP6Iz6pfGNP+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedAfham/COVID-19-Cough-Detection/blob/master/Cough_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_i65i3x8XwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "from librosa import display\n",
        "import numpy as np\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import random\n",
        "import cv2 as cv\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "#import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "#tf.disable_v2_behavior()\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten,BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation,ReLU,LeakyReLU\n",
        "from tensorflow.keras.models import load_model\n",
        "#from tensorflow.keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler,Callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ebPsz_78aGK",
        "colab_type": "code",
        "outputId": "f22d8e4f-bfde-4b8f-f784-970c0d7bcdaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr44hQsMQUpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_audio(audio_directory,audio_file):\n",
        "  audio,sampling_rate = librosa.load(audio_directory+audio_file)\n",
        "  return (audio,sampling_rate)\n",
        "\n",
        "def volume_aug(audio):\n",
        "  factor_list = [0.5,1,1.5,2]\n",
        "  factor = factor_list[np.random.randint(0,4)]\n",
        "  augmented_samples = audio * factor\n",
        "  return augmented_samples\n",
        "\n",
        "def bg_noise_aug(audio,bg_noise):\n",
        "  length = len(audio)\n",
        "  rand_start = np.random.randint(0,len(bg_noise)- length)\n",
        "  augmented_audio = audio + bg_noise[rand_start:rand_start + length]\n",
        "  return augmented_audio\n",
        "\n",
        "def spect(audio):\n",
        "  NFFT = 512\n",
        "  f, t, Sxx = scipy.signal.spectrogram(x=audio,fs=sampling_rate,window=np.hamming(NFFT),nfft=NFFT,noverlap=int(NFFT/3),nperseg=NFFT,mode='magnitude')\n",
        "  spectrum = 20*np.log10(Sxx)\n",
        "  spectrum = spectrum.ravel().reshape(257,321,1)\n",
        "  return spectrum\n",
        "\n",
        "def melspectrogram(audio,sampling_rate):  #no of mels means no of mel filters\n",
        "    #samples, sampling_rate = librosa.core.load(directory + audio_file)   #loading data set\n",
        "    samples = audio\n",
        "    frame_size = 0.025\n",
        "    frame_stride = frame_size * 0.7\n",
        "    no_of_mels = 128\n",
        "    frame_length, frame_step = frame_size * sampling_rate, frame_stride * sampling_rate  \n",
        "    frame_length = int(round(frame_length))\n",
        "    frame_step = int(round(frame_step))\n",
        "    samples_length = len(samples)\n",
        "    num_frames = int(np.ceil(float(np.abs(samples_length - frame_length)) / frame_step))\n",
        "\n",
        "    pad_samples_length = num_frames * frame_step + frame_length\n",
        "    z = np.zeros((pad_samples_length - samples_length))\n",
        "    pad_samples = np.append(samples, z)  #zero padding\n",
        "       \n",
        "    spect_samples = np.abs(librosa.stft(pad_samples, n_fft=frame_length, hop_length=frame_step, window=np.hamming(frame_length))) #calculating stft \n",
        "    spect_samples = librosa.amplitude_to_db(spect_samples, ref=np.max)\n",
        "    mel_filter = librosa.filters.mel(sampling_rate, frame_length, n_mels=128, fmin=0, fmax=None)  #calculating mel filter array\n",
        "    \n",
        "    mel_spect_samples = np.dot(mel_filter, spect_samples)   #calculating mel spectrogram\n",
        "    spectrum = mel_spect_samples.ravel().reshape(128,287,1)\n",
        "    #spectrum = mel_spect_samples\n",
        "    return spectrum\n",
        "\n",
        "def normalize_spectrum(spectrum):\n",
        "  return (spectrum - np.mean(spectrum))/np.std(spectrum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wAc65FDdquC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bg_noise_dir = ['Station.wav','NeighbourSpeaking.wav','Metro.wav','Hallway.wav','FootSteps.wav','AirportAnnouncements.wav']\n",
        "audio_directory = 'gdrive/My Drive/Cough Detection/Sounds/Background Noise/'\n",
        "bg_noise_list = []\n",
        "for noise in range(len(bg_noise_dir)):\n",
        "  audio_file = bg_noise_dir[noise]\n",
        "  noise_add = read_audio(audio_directory,audio_file)[0]\n",
        "  bg_noise_list.append(noise_add)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJRjMhmAiOEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d7d1eb7-81d6-4543-9317-892fa45118ac"
      },
      "source": [
        "audio_directory = \"gdrive/My Drive/Cough Detection/Sounds/Cough/\"\n",
        "audio,sampling_rate = read_audio(audio_directory,\"cough - 56a.wav\")\n",
        "spectrum = melspectrogram(audio)\n",
        "spectrum.shape"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 287)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T9NOQoUZGx5",
        "colab_type": "code",
        "outputId": "18bf8ae3-3b9b-4e46-fcff-cbac79d9a0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "audio_directory = \"gdrive/My Drive/Cough Detection/Sounds/\"\n",
        "non_cough = os.listdir(audio_directory+\"Audio/\")\n",
        "cough = os.listdir(audio_directory+\"Cough/\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twqEWdWlZ6Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_cough = random.sample(cough,45)\n",
        "test_non_cough = random.sample(non_cough,45)\n",
        "\n",
        "train_val_cough = list(set(cough) - set(test_cough))\n",
        "train_val_non_cough = list(set(non_cough) - set(test_non_cough))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk3Dv2pFlZSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_val_cough = np.load('gdrive/My Drive/Cough Detection/Numpy Arrays/train_val_cough.npy').tolist()\n",
        "#train_val_cough = [np.array(xi) for xi in train_val_cough]\n",
        "\n",
        "#non_cough_audio = np.load('gdrive/My Drive/Cough Detection/Numpy Arrays/non_cough_train_val.npy').tolist()\n",
        "#non_cough_audio = [np.array(xi) for xi in non_cough_audio]\n",
        "\n",
        "#test_cough = np.load('gdrive/My Drive/Cough Detection/Numpy Arrays/test_cough.npy').tolist()\n",
        "#test_cough = [np.array(xi) for xi in test_cough]\n",
        "\n",
        "#test_non_cough_audio = np.load('gdrive/My Drive/Cough Detection/Numpy Arrays/non_cough_test.npy').tolist()\n",
        "#test_non_cough_audio = [np.array(xi) for xi in test_non_cough_audio]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NHAC1wXhYsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.shuffle(train_val_cough)\n",
        "train_cough,val_cough = train_val_cough[:int(len(train_val_cough)*0.9)], train_val_cough[int(len(train_val_cough)*0.9):]\n",
        "\n",
        "random.shuffle(train_val_non_cough)\n",
        "train_non_cough,val_non_cough = train_val_non_cough[:int(len(train_val_non_cough)*0.9)], train_val_non_cough[int(len(train_val_non_cough)*0.9):]\n",
        "\n",
        "train_files = [train_non_cough, train_cough]\n",
        "val_files = [val_non_cough, val_cough]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCyCUrbIGAmr",
        "colab_type": "text"
      },
      "source": [
        "**For the arrays with augmentation model.fit_generator() function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEbDMeXQ70LN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generator Function\n",
        "def generator(batch_size, is_train):\n",
        "  if is_train:\n",
        "    audio_list = train_files\n",
        "  else:\n",
        "    audio_list = val_files\n",
        "\n",
        "  while True:\n",
        "    batch_features = np.zeros((batch_size,128,287,1))\n",
        "    batch_labels = np.zeros((batch_size,1))\n",
        "    rand_list = [[],[]]\n",
        "    for n in range(batch_size):\n",
        "      while True:\n",
        "        label = np.random.randint(0,2)\n",
        "        if label == 1:\n",
        "          audio_directory = \"gdrive/My Drive/Cough Detection/Sounds/Cough/\"\n",
        "        elif label ==0:\n",
        "          audio_directory = \"gdrive/My Drive/Cough Detection/Sounds/Audio/\"\n",
        "\n",
        "        rand_audio = random.sample(audio_list[label],1)[0]\n",
        "        if rand_audio not in rand_list[label]:\n",
        "          rand_list[label].append(rand_audio)\n",
        "          selected_audio,sampling_rate = read_audio(audio_directory,rand_audio)\n",
        "          if len(selected_audio) != 110250:\n",
        "            length = int(5.0 * sampling_rate)\n",
        "            audio = librosa.util.fix_length(selected_audio,length)\n",
        "            noise = np.random.randn(len(audio)) * 0.0005\n",
        "            selected_audio = audio + noise\n",
        "          volume_aug_audio = volume_aug(selected_audio)\n",
        "          rand_noise = random.randrange(len(bg_noise_list))\n",
        "          bg_noise = bg_noise_list[rand_noise]\n",
        "          bg_noise_added = bg_noise_aug(volume_aug_audio,bg_noise)\n",
        "          spectrum = melspectrogram(bg_noise_added,sampling_rate)\n",
        "          batch_features[n] = normalize_spectrum(spectrum)\n",
        "          batch_labels[n] = label\n",
        "          break\n",
        "\n",
        "    yield batch_features,batch_labels\n",
        "\n",
        "#Callbacks\n",
        "trained_model_path_Adam = 'gdrive/My Drive/Cough Detection/Pre trained Models/model-{val_accuracy:.2f}-Adam.h5'\n",
        "checkpoint_Adam = ModelCheckpoint(trained_model_path_Adam, \n",
        "                             monitor='val_accuracy', \n",
        "                             save_best_only=True, \n",
        "                             mode='max', \n",
        "                             period=1)\n",
        "\n",
        "trained_model_path_SGD= 'gdrive/My Drive/Cough Detection/Pre trained Models/model-{val_accuracy:.2f}-SGD.h5'\n",
        "checkpoint_SGD = ModelCheckpoint(trained_model_path_SGD, \n",
        "                             monitor='val_accuracy', \n",
        "                             save_best_only=True, \n",
        "                             mode='max', \n",
        "                             period=1)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', \n",
        "                           min_delta=0.001, \n",
        "                           patience=50, \n",
        "                           mode='max',\n",
        "                           restore_best_weights=False)\n",
        "\n",
        "def step_decay(epoch):\n",
        "   initial_rate = 0.01\n",
        "   drop = 0.5\n",
        "   epochs_drop = 10.0\n",
        "   lrate = initial_rate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
        "   return lrate\n",
        "\n",
        "step_scheduler  = LearningRateScheduler(step_decay)\n",
        "\n",
        "#Model \n",
        "shape = (128,287,1)\n",
        "model = Sequential()\n",
        "\n",
        "#Layer 1 \n",
        "model.add(MaxPooling2D(pool_size=(2,2),input_shape=shape,name='MaxPooling2D_1'))\n",
        "model.add(Conv2D(32, kernel_size=(5,5),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=(4,4)))\n",
        "\n",
        "#Layer 2\n",
        "model.add(Conv2D(64, kernel_size=(5,5),padding='same',name='Conv2D_2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),name='MaxPooling2D_3'))\n",
        "\n",
        "model.add(Flatten(name = 'Flatten'))\n",
        "\n",
        "#Layer 3\n",
        "#model.add(Dense(256,name = 'Dense_1'))\n",
        "#model.add(BatchNormalization(name = 'BatchNormalization_2'))\n",
        "#model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(Dropout(0.5,name = 'Dropout_1'))\n",
        "\n",
        "#Layer 4\n",
        "model.add(Dense(128,name = 'Dense_2'))\n",
        "model.add(BatchNormalization(name = 'BatchNormalization_3'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(0.5,name = 'Dropout_2'))\n",
        "\n",
        "#Layer 5\n",
        "model.add(Dense(128,name = 'Dense_3'))\n",
        "model.add(BatchNormalization(name = 'BatchNormalization_4'))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "#model.add(Dropout(0.5,name = 'Dropout_3'))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid',name = 'Dense_4'))\n",
        "\n",
        "adam = keras.optimizers.Adam(learning_rate =1e-2, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "model.compile(optimizer= adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "batch_size = 17\n",
        "history = model.fit_generator(generator(batch_size,True), epochs=150,steps_per_epoch=50, validation_data=generator(batch_size,False),validation_steps=20,callbacks = [checkpoint_Adam,step_scheduler,early_stop])\n",
        "x = model.optimizer.lr\n",
        "tf.print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHnW2vF57Ujx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cont = keras.models.load_model('gdrive/My Drive/Cough Detection/Pre trained Models/model-0.97-Adam_best.h5')\n",
        "\n",
        "def step_decay(epoch):\n",
        "   initial_rate = 3e-3\n",
        "   drop = 0.5\n",
        "   epochs_drop = 10.0\n",
        "   lrate = initial_rate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
        "   return lrate\n",
        "\n",
        "step_scheduler  = LearningRateScheduler(step_decay)\n",
        "sgd = keras.optimizers.SGD(learning_rate=3e-3, momentum=0.98, nesterov=False)\n",
        "model_cont.compile(optimizer= sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "batch_size = 17\n",
        "history = model_cont.fit_generator(generator(batch_size,True), epochs=150,steps_per_epoch=50, validation_data=generator(batch_size,False),validation_steps=17,callbacks = [checkpoint_SGD,early_stop,step_scheduler])\n",
        "x = model_cont.optimizer.lr\n",
        "tf.print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZFHLQt8LZIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  fig ,ax = plt.subplots()\n",
        "ax.plot(history.history['accuracy'])\n",
        "ax.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "fig.savefig('gdrive/My Drive/Cough Detection/Accuracy Loss plots/acc_sgd.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjESisUMUFyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig ,ax = plt.subplots()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "fig.savefig('gdrive/My Drive/Cough Detection/Accuracy Loss plots/loss_sgd.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVpEjMO3zgxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare the test data\n",
        "random.shuffle(test_non_cough)\n",
        "random.shuffle(test_cough)\n",
        "\n",
        "test_data= [test_non_cough,test_cough]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNwQEGIPryDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = len(test_data[1]) + len(test_data[0])\n",
        "model_data = np.zeros((n_input,257,321,1))\n",
        "model_label = np.zeros((n_input,1))\n",
        "data_list = [[],[]]\n",
        "\n",
        "for i in range(n_input):\n",
        "  while True:\n",
        "    label = np.random.randint(0,2)\n",
        "    rand_num = random.randrange(len(test_data[label]))\n",
        "    if rand_num not in data_list[label]:\n",
        "      data_list[label].append(rand_num)\n",
        "      selected_audio = test_data[label][rand_num]\n",
        "      volume_aug_audio = volume_aug(selected_audio)\n",
        "      rand_noise = random.randrange(len(bg_noise_list))\n",
        "      bg_noise = bg_noise_list[rand_noise]\n",
        "      bg_noise_added = bg_noise_aug(volume_aug_audio,bg_noise)\n",
        "      spectrum = spect(bg_noise_added)\n",
        "      model_data[i] = normalize_spectrum(spectrum)\n",
        "      model_label[i] = label\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFmHQKWjKOrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_model = keras.models.load_model('gdrive/My Drive/Cough Detection/Pre trained Models/model-0.97-Adam_best.h5')\n",
        "#test_model = keras.models.load_model('gdrive/My Drive/Cough Detection/Pre trained Models/model-0.97-SGD.h5')\n",
        "\n",
        "pred = test_model.predict(x = model_data,batch_size = n_input)\n",
        "print (test_model.evaluate(x = model_data, y = model_label,batch_size=n_input))\n",
        "preds = np.array([int(np.round(pred[i]+0.05)) for i in range(len(pred))])\n",
        "\n",
        "\n",
        "print (confusion_matrix(model_label,preds))\n",
        "print ('\\n')\n",
        "print (classification_report(model_label,preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Wmg6X34zT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_keras = pred.ravel()\n",
        "y_test = model_label.ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCmy3kkV5vko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFbqAD1r6W2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auc_keras = auc(fpr_keras, tpr_keras)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRSmfW356ZjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "fig.savefig('gdrive/My Drive/Cough Detection/Accuracy Loss plots/ROC_adam.png')\n",
        "\n",
        "plt.figure(2)\n",
        "plt.xlim(0, 0.2)\n",
        "plt.ylim(0.8, 1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve (zoomed in at top left)')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjOKWKP8CQ3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}